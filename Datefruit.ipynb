{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9a6cb06b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "\n",
    "from sklearn.model_selection import  train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler, OneHotEncoder\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import  TensorDataset, DataLoader\n",
    "import torch.optim as optim\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0d4c17a3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AREA</th>\n",
       "      <th>PERIMETER</th>\n",
       "      <th>MAJOR_AXIS</th>\n",
       "      <th>MINOR_AXIS</th>\n",
       "      <th>ECCENTRICITY</th>\n",
       "      <th>EQDIASQ</th>\n",
       "      <th>SOLIDITY</th>\n",
       "      <th>CONVEX_AREA</th>\n",
       "      <th>EXTENT</th>\n",
       "      <th>ASPECT_RATIO</th>\n",
       "      <th>...</th>\n",
       "      <th>KurtosisRR</th>\n",
       "      <th>KurtosisRG</th>\n",
       "      <th>KurtosisRB</th>\n",
       "      <th>EntropyRR</th>\n",
       "      <th>EntropyRG</th>\n",
       "      <th>EntropyRB</th>\n",
       "      <th>ALLdaub4RR</th>\n",
       "      <th>ALLdaub4RG</th>\n",
       "      <th>ALLdaub4RB</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>422163</td>\n",
       "      <td>2378.908</td>\n",
       "      <td>837.8484</td>\n",
       "      <td>645.6693</td>\n",
       "      <td>0.6373</td>\n",
       "      <td>733.1539</td>\n",
       "      <td>0.9947</td>\n",
       "      <td>424428</td>\n",
       "      <td>0.7831</td>\n",
       "      <td>1.2976</td>\n",
       "      <td>...</td>\n",
       "      <td>3.2370</td>\n",
       "      <td>2.9574</td>\n",
       "      <td>4.2287</td>\n",
       "      <td>-59191263232</td>\n",
       "      <td>-50714214400</td>\n",
       "      <td>-39922372608</td>\n",
       "      <td>58.7255</td>\n",
       "      <td>54.9554</td>\n",
       "      <td>47.8400</td>\n",
       "      <td>BERHI</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>338136</td>\n",
       "      <td>2085.144</td>\n",
       "      <td>723.8198</td>\n",
       "      <td>595.2073</td>\n",
       "      <td>0.5690</td>\n",
       "      <td>656.1464</td>\n",
       "      <td>0.9974</td>\n",
       "      <td>339014</td>\n",
       "      <td>0.7795</td>\n",
       "      <td>1.2161</td>\n",
       "      <td>...</td>\n",
       "      <td>2.6228</td>\n",
       "      <td>2.6350</td>\n",
       "      <td>3.1704</td>\n",
       "      <td>-34233065472</td>\n",
       "      <td>-37462601728</td>\n",
       "      <td>-31477794816</td>\n",
       "      <td>50.0259</td>\n",
       "      <td>52.8168</td>\n",
       "      <td>47.8315</td>\n",
       "      <td>BERHI</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>526843</td>\n",
       "      <td>2647.394</td>\n",
       "      <td>940.7379</td>\n",
       "      <td>715.3638</td>\n",
       "      <td>0.6494</td>\n",
       "      <td>819.0222</td>\n",
       "      <td>0.9962</td>\n",
       "      <td>528876</td>\n",
       "      <td>0.7657</td>\n",
       "      <td>1.3150</td>\n",
       "      <td>...</td>\n",
       "      <td>3.7516</td>\n",
       "      <td>3.8611</td>\n",
       "      <td>4.7192</td>\n",
       "      <td>-93948354560</td>\n",
       "      <td>-74738221056</td>\n",
       "      <td>-60311207936</td>\n",
       "      <td>65.4772</td>\n",
       "      <td>59.2860</td>\n",
       "      <td>51.9378</td>\n",
       "      <td>BERHI</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>416063</td>\n",
       "      <td>2351.210</td>\n",
       "      <td>827.9804</td>\n",
       "      <td>645.2988</td>\n",
       "      <td>0.6266</td>\n",
       "      <td>727.8378</td>\n",
       "      <td>0.9948</td>\n",
       "      <td>418255</td>\n",
       "      <td>0.7759</td>\n",
       "      <td>1.2831</td>\n",
       "      <td>...</td>\n",
       "      <td>5.0401</td>\n",
       "      <td>8.6136</td>\n",
       "      <td>8.2618</td>\n",
       "      <td>-32074307584</td>\n",
       "      <td>-32060925952</td>\n",
       "      <td>-29575010304</td>\n",
       "      <td>43.3900</td>\n",
       "      <td>44.1259</td>\n",
       "      <td>41.1882</td>\n",
       "      <td>BERHI</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>347562</td>\n",
       "      <td>2160.354</td>\n",
       "      <td>763.9877</td>\n",
       "      <td>582.8359</td>\n",
       "      <td>0.6465</td>\n",
       "      <td>665.2291</td>\n",
       "      <td>0.9908</td>\n",
       "      <td>350797</td>\n",
       "      <td>0.7569</td>\n",
       "      <td>1.3108</td>\n",
       "      <td>...</td>\n",
       "      <td>2.7016</td>\n",
       "      <td>2.9761</td>\n",
       "      <td>4.4146</td>\n",
       "      <td>-39980974080</td>\n",
       "      <td>-35980042240</td>\n",
       "      <td>-25593278464</td>\n",
       "      <td>52.7743</td>\n",
       "      <td>50.9080</td>\n",
       "      <td>42.6666</td>\n",
       "      <td>BERHI</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 35 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     AREA  PERIMETER  MAJOR_AXIS  MINOR_AXIS  ECCENTRICITY   EQDIASQ  \\\n",
       "0  422163   2378.908    837.8484    645.6693        0.6373  733.1539   \n",
       "1  338136   2085.144    723.8198    595.2073        0.5690  656.1464   \n",
       "2  526843   2647.394    940.7379    715.3638        0.6494  819.0222   \n",
       "3  416063   2351.210    827.9804    645.2988        0.6266  727.8378   \n",
       "4  347562   2160.354    763.9877    582.8359        0.6465  665.2291   \n",
       "\n",
       "   SOLIDITY  CONVEX_AREA  EXTENT  ASPECT_RATIO  ...  KurtosisRR  KurtosisRG  \\\n",
       "0    0.9947       424428  0.7831        1.2976  ...      3.2370      2.9574   \n",
       "1    0.9974       339014  0.7795        1.2161  ...      2.6228      2.6350   \n",
       "2    0.9962       528876  0.7657        1.3150  ...      3.7516      3.8611   \n",
       "3    0.9948       418255  0.7759        1.2831  ...      5.0401      8.6136   \n",
       "4    0.9908       350797  0.7569        1.3108  ...      2.7016      2.9761   \n",
       "\n",
       "   KurtosisRB    EntropyRR    EntropyRG    EntropyRB  ALLdaub4RR  ALLdaub4RG  \\\n",
       "0      4.2287 -59191263232 -50714214400 -39922372608     58.7255     54.9554   \n",
       "1      3.1704 -34233065472 -37462601728 -31477794816     50.0259     52.8168   \n",
       "2      4.7192 -93948354560 -74738221056 -60311207936     65.4772     59.2860   \n",
       "3      8.2618 -32074307584 -32060925952 -29575010304     43.3900     44.1259   \n",
       "4      4.4146 -39980974080 -35980042240 -25593278464     52.7743     50.9080   \n",
       "\n",
       "   ALLdaub4RB  Class  \n",
       "0     47.8400  BERHI  \n",
       "1     47.8315  BERHI  \n",
       "2     51.9378  BERHI  \n",
       "3     41.1882  BERHI  \n",
       "4     42.6666  BERHI  \n",
       "\n",
       "[5 rows x 35 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(r\"C:\\Users\\pc\\OneDrive\\Music\\Desktop\\ML_Projects\\Dataset\\DateFruit_Dataset.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f0b4785d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 898 entries, 0 to 897\n",
      "Data columns (total 35 columns):\n",
      " #   Column         Non-Null Count  Dtype  \n",
      "---  ------         --------------  -----  \n",
      " 0   AREA           898 non-null    int64  \n",
      " 1   PERIMETER      898 non-null    float64\n",
      " 2   MAJOR_AXIS     898 non-null    float64\n",
      " 3   MINOR_AXIS     898 non-null    float64\n",
      " 4   ECCENTRICITY   898 non-null    float64\n",
      " 5   EQDIASQ        898 non-null    float64\n",
      " 6   SOLIDITY       898 non-null    float64\n",
      " 7   CONVEX_AREA    898 non-null    int64  \n",
      " 8   EXTENT         898 non-null    float64\n",
      " 9   ASPECT_RATIO   898 non-null    float64\n",
      " 10  ROUNDNESS      898 non-null    float64\n",
      " 11  COMPACTNESS    898 non-null    float64\n",
      " 12  SHAPEFACTOR_1  898 non-null    float64\n",
      " 13  SHAPEFACTOR_2  898 non-null    float64\n",
      " 14  SHAPEFACTOR_3  898 non-null    float64\n",
      " 15  SHAPEFACTOR_4  898 non-null    float64\n",
      " 16  MeanRR         898 non-null    float64\n",
      " 17  MeanRG         898 non-null    float64\n",
      " 18  MeanRB         898 non-null    float64\n",
      " 19  StdDevRR       898 non-null    float64\n",
      " 20  StdDevRG       898 non-null    float64\n",
      " 21  StdDevRB       898 non-null    float64\n",
      " 22  SkewRR         898 non-null    float64\n",
      " 23  SkewRG         898 non-null    float64\n",
      " 24  SkewRB         898 non-null    float64\n",
      " 25  KurtosisRR     898 non-null    float64\n",
      " 26  KurtosisRG     898 non-null    float64\n",
      " 27  KurtosisRB     898 non-null    float64\n",
      " 28  EntropyRR      898 non-null    int64  \n",
      " 29  EntropyRG      898 non-null    int64  \n",
      " 30  EntropyRB      898 non-null    int64  \n",
      " 31  ALLdaub4RR     898 non-null    float64\n",
      " 32  ALLdaub4RG     898 non-null    float64\n",
      " 33  ALLdaub4RB     898 non-null    float64\n",
      " 34  Class          898 non-null    object \n",
      "dtypes: float64(29), int64(5), object(1)\n",
      "memory usage: 245.7+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3c913d86",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split X, Y Value\n",
    "\n",
    "x = df.drop([\"Class\"], axis=1)\n",
    "y = df[\"Class\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9f5237e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# y Labeling\n",
    "\n",
    "le = LabelEncoder()\n",
    "y = le.fit_transform(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c0550be7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train Test Split\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=42, stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "97e7952b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# X Scaling\n",
    "\n",
    "scaler = StandardScaler()\n",
    "x_train_scaled = scaler.fit_transform(x_train)\n",
    "x_test_scaled = scaler.transform(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2ebea66b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert data into Tensor Dataset\n",
    "\n",
    "x_train_tensor = torch.tensor(x_train_scaled, dtype=torch.float32)\n",
    "x_test_tensor = torch.tensor(x_test_scaled, dtype=torch.float32)\n",
    "\n",
    "y_train_tensor = torch.tensor(y_train, dtype=torch.long)\n",
    "y_test_tensor = torch.tensor(y_test, dtype=torch.long)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "23d0e0c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TensorDataset / Dataloader \n",
    "\n",
    "train_dataset = TensorDataset(x_train_tensor, y_train_tensor)\n",
    "test_dataset = TensorDataset(x_test_tensor, y_test_tensor)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True) \n",
    "test_loader = DataLoader(test_dataset, batch_size=32)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3e1df580",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ANN Model\n",
    "\n",
    "class ANN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ANN, self).__init__()\n",
    "        \n",
    "        self.model = nn.Sequential(\n",
    "            nn.Linear(x_train.shape[1], 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(64, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(64, 7)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.model(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "706a4870",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ANN()\n",
    "\n",
    "# Loss & Optim\n",
    "\n",
    "criteria = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6c3a5643",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch = 1 / 0, loss = 1.657151180764903\n",
      "epoch = 2 / 1, loss = 1.054980404998945\n",
      "epoch = 3 / 2, loss = 0.7026288742604463\n",
      "epoch = 4 / 3, loss = 0.5195430491281592\n",
      "epoch = 5 / 4, loss = 0.43303354732368304\n",
      "epoch = 6 / 5, loss = 0.37876219334809674\n",
      "epoch = 7 / 6, loss = 0.3383388085209805\n",
      "epoch = 8 / 7, loss = 0.3093888642995254\n",
      "epoch = 9 / 8, loss = 0.2889636223730834\n",
      "epoch = 10 / 9, loss = 0.2575336409651715\n",
      "epoch = 11 / 10, loss = 0.23157226391460584\n",
      "epoch = 12 / 11, loss = 0.21935844972081806\n",
      "epoch = 13 / 12, loss = 0.2056365592972092\n",
      "epoch = 14 / 13, loss = 0.19538292223992554\n",
      "epoch = 15 / 14, loss = 0.18277630533861078\n",
      "epoch = 16 / 15, loss = 0.1725177152649216\n",
      "epoch = 17 / 16, loss = 0.16728982880063678\n",
      "epoch = 18 / 17, loss = 0.16035886432813562\n",
      "epoch = 19 / 18, loss = 0.15025805066461148\n",
      "epoch = 20 / 19, loss = 0.15027487569529077\n",
      "epoch = 21 / 20, loss = 0.13705554377773535\n",
      "epoch = 22 / 21, loss = 0.13197057135403156\n",
      "epoch = 23 / 22, loss = 0.12767039150323556\n",
      "epoch = 24 / 23, loss = 0.11967645310189413\n",
      "epoch = 25 / 24, loss = 0.11615836474558582\n",
      "epoch = 26 / 25, loss = 0.11557709279915561\n",
      "epoch = 27 / 26, loss = 0.10528416858743066\n",
      "epoch = 28 / 27, loss = 0.10813866766250652\n",
      "epoch = 29 / 28, loss = 0.10108601674437523\n",
      "epoch = 30 / 29, loss = 0.10265330840712009\n",
      "epoch = 31 / 30, loss = 0.097217022360343\n",
      "epoch = 32 / 31, loss = 0.10424120465050572\n",
      "epoch = 33 / 32, loss = 0.09050426567378252\n",
      "epoch = 34 / 33, loss = 0.09111173580522122\n",
      "epoch = 35 / 34, loss = 0.08972396037500838\n",
      "epoch = 36 / 35, loss = 0.09279374689187693\n",
      "epoch = 37 / 36, loss = 0.08077400793199954\n",
      "epoch = 38 / 37, loss = 0.07841553024785675\n",
      "epoch = 39 / 38, loss = 0.07933263926078445\n",
      "epoch = 40 / 39, loss = 0.08528375471739666\n",
      "epoch = 41 / 40, loss = 0.07359483603226102\n",
      "epoch = 42 / 41, loss = 0.07115770586887779\n",
      "epoch = 43 / 42, loss = 0.07047912502742332\n",
      "epoch = 44 / 43, loss = 0.06918862510634505\n",
      "epoch = 45 / 44, loss = 0.07073409928251868\n",
      "epoch = 46 / 45, loss = 0.06140829367644113\n",
      "epoch = 47 / 46, loss = 0.06402958451729754\n",
      "epoch = 48 / 47, loss = 0.06505920620554168\n",
      "epoch = 49 / 48, loss = 0.05635881019027337\n",
      "epoch = 50 / 49, loss = 0.06020425276263901\n",
      "epoch = 51 / 50, loss = 0.05973282221542752\n",
      "epoch = 52 / 51, loss = 0.052846516684993454\n",
      "epoch = 53 / 52, loss = 0.05959505834819182\n",
      "epoch = 54 / 53, loss = 0.050388468267477074\n",
      "epoch = 55 / 54, loss = 0.04954365758306306\n",
      "epoch = 56 / 55, loss = 0.04622115972249404\n",
      "epoch = 57 / 56, loss = 0.04623266580798056\n",
      "epoch = 58 / 57, loss = 0.043088464511801365\n",
      "epoch = 59 / 58, loss = 0.049921254485683596\n",
      "epoch = 60 / 59, loss = 0.050462034004537956\n",
      "epoch = 61 / 60, loss = 0.04020253724276857\n",
      "epoch = 62 / 61, loss = 0.047250377824125084\n",
      "epoch = 63 / 62, loss = 0.038169793339203235\n",
      "epoch = 64 / 63, loss = 0.03689360788658909\n",
      "epoch = 65 / 64, loss = 0.0355803804350612\n",
      "epoch = 66 / 65, loss = 0.03892523408664957\n",
      "epoch = 67 / 66, loss = 0.03477339503233847\n",
      "epoch = 68 / 67, loss = 0.03273414377042133\n",
      "epoch = 69 / 68, loss = 0.03811500739792119\n",
      "epoch = 70 / 69, loss = 0.035172481413768684\n",
      "epoch = 71 / 70, loss = 0.030977811542866024\n",
      "epoch = 72 / 71, loss = 0.03215103337298269\n",
      "epoch = 73 / 72, loss = 0.03192048169591505\n",
      "epoch = 74 / 73, loss = 0.02996203319027858\n",
      "epoch = 75 / 74, loss = 0.028097742844534958\n",
      "epoch = 76 / 75, loss = 0.030728111246033855\n",
      "epoch = 77 / 76, loss = 0.03954727321093821\n",
      "epoch = 78 / 77, loss = 0.046601925450174705\n",
      "epoch = 79 / 78, loss = 0.03093522509721958\n",
      "epoch = 80 / 79, loss = 0.02235645851444291\n",
      "epoch = 81 / 80, loss = 0.022650761371630284\n",
      "epoch = 82 / 81, loss = 0.02182601809339679\n",
      "epoch = 83 / 82, loss = 0.020869275656245325\n",
      "epoch = 84 / 83, loss = 0.02331168034478374\n",
      "epoch = 85 / 84, loss = 0.023915641308438196\n",
      "epoch = 86 / 85, loss = 0.02141481595437812\n",
      "epoch = 87 / 86, loss = 0.021112602042115253\n",
      "epoch = 88 / 87, loss = 0.019821803723259465\n",
      "epoch = 89 / 88, loss = 0.021677515869352803\n",
      "epoch = 90 / 89, loss = 0.02040869791222655\n",
      "epoch = 91 / 90, loss = 0.01943642277594494\n",
      "epoch = 92 / 91, loss = 0.01915667713214846\n",
      "epoch = 93 / 92, loss = 0.01616298055033321\n",
      "epoch = 94 / 93, loss = 0.017473978668694264\n",
      "epoch = 95 / 94, loss = 0.015296568871354279\n",
      "epoch = 96 / 95, loss = 0.019049332112721775\n",
      "epoch = 97 / 96, loss = 0.02056759480467957\n",
      "epoch = 98 / 97, loss = 0.017933668629468782\n",
      "epoch = 99 / 98, loss = 0.014842393246236379\n",
      "epoch = 100 / 99, loss = 0.017429613376684163\n"
     ]
    }
   ],
   "source": [
    "# Training the Neural Network\n",
    "\n",
    "epochs = 100\n",
    "for epoch in range(epochs):\n",
    "    model.train()\n",
    "\n",
    "    running_loss = 0.0\n",
    "\n",
    "    for xb, yb in train_loader:\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        outputs = model(xb)\n",
    "        loss = criteria(outputs, yb)\n",
    "        loss.backward()\n",
    "        optimizer.step()    # Params Update\n",
    "\n",
    "        running_loss += loss.item()\n",
    "\n",
    "    train_loss = running_loss / len(train_loader)  \n",
    "\n",
    "    print(f\"epoch = {epoch+1} / {epoch}, loss = {train_loss}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "af255cf6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  93.88888888888889\n"
     ]
    }
   ],
   "source": [
    "# Evaluate\n",
    "\n",
    "model.eval()\n",
    "\n",
    "total = 0\n",
    "correct = 0\n",
    "\n",
    "with torch.no_grad():\n",
    "    for xb, yb in test_loader:\n",
    "        outputs = model(xb) # [0.2, 0.5, 1,3, -0.5, ..] - 7 vals\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "\n",
    "        correct += (predicted == yb).sum().item()\n",
    "        total += yb.size(0) # Actual samples in each batch\n",
    "\n",
    "print(\"Accuracy: \", correct/total*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ca3a4663",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving Model\n",
    "\n",
    "torch.save(model.state_dict(), \"best_datefruite_model.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ed372662",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Loading Model\n",
    "\n",
    "model.load_state_dict(torch.load(\"best_datefruite_model.pt\"))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
